{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "696836bd",
   "metadata": {},
   "source": [
    "# Pipeline Engine — Interactive Demo\n",
    "\n",
    "This notebook walks through every feature of the generic pipeline engine.\n",
    "Each cell is self-contained — run them top to bottom.\n",
    "\n",
    "**No external dependencies** — only the `pipeline/` package."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0704c7",
   "metadata": {},
   "source": [
    "## Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135705a5",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "import sys, os, time\n",
    "from types import MappingProxyType\n",
    "\n",
    "# ensure the project root is on the path (needed when running from examples/)\n",
    "sys.path.insert(0, os.path.join(os.path.dirname(__file__), \"..\") if \"__file__\" in dir() else \"..\")\n",
    "\n",
    "from pipeline import (\n",
    "    Pipeline,\n",
    "    Branch,\n",
    "    MergeStrategy,\n",
    "    StepContext,\n",
    "    SampleResult,\n",
    "    PipelineOrderError,\n",
    "    BranchError,\n",
    ")\n",
    "\n",
    "def show(results: list[SampleResult]) -> None:\n",
    "    \"\"\"Pretty-print a list of SampleResult.\"\"\"\n",
    "    for r in results:\n",
    "        tag = \"OK\" if r.error is None else f\"FAIL @ {r.failed_at}\"\n",
    "        print(f\"  [{tag}] sample={r.sample!r}\")\n",
    "        if r.output:\n",
    "            named = {k: getattr(r.output, k) for k in (\"agent_output\", \"environment_result\", \"reflection\") if getattr(r.output, k) is not None}\n",
    "            if named:\n",
    "                print(f\"         fields:   {named}\")\n",
    "            meta = dict(r.output.metadata)\n",
    "            if meta:\n",
    "                print(f\"         metadata: {meta}\")\n",
    "        if r.error:\n",
    "            print(f\"         error:    {r.error}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac62c4a4",
   "metadata": {},
   "source": [
    "## Step Definitions\n",
    "\n",
    "A **step** is any object with:\n",
    "- `requires: frozenset[str]` — metadata keys it reads\n",
    "- `provides: frozenset[str]` — metadata keys it writes\n",
    "- `__call__(ctx: StepContext) -> StepContext`\n",
    "\n",
    "No base class — pure duck typing via `StepProtocol`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3802f693",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class Tokenize:\n",
    "    \"\"\"Split sample text into words, store token list and count.\"\"\"\n",
    "    requires = frozenset()\n",
    "    provides = frozenset({\"tokens\", \"word_count\"})\n",
    "\n",
    "    def __call__(self, ctx: StepContext) -> StepContext:\n",
    "        tokens = str(ctx.sample).split()\n",
    "        print(f\"    [Tokenize]  '{ctx.sample}' → {len(tokens)} tokens\")\n",
    "        return ctx.replace(metadata=MappingProxyType({\n",
    "            **ctx.metadata, \"tokens\": tokens, \"word_count\": len(tokens),\n",
    "        }))\n",
    "\n",
    "\n",
    "class Uppercase:\n",
    "    \"\"\"Uppercase each token. Requires 'tokens' in metadata.\"\"\"\n",
    "    requires = frozenset({\"tokens\"})\n",
    "    provides = frozenset({\"upper_tokens\"})\n",
    "\n",
    "    def __call__(self, ctx: StepContext) -> StepContext:\n",
    "        upper = [t.upper() for t in ctx.metadata[\"tokens\"]]\n",
    "        print(f\"    [Uppercase] {ctx.metadata['tokens']} → {upper}\")\n",
    "        return ctx.replace(metadata=MappingProxyType({**ctx.metadata, \"upper_tokens\": upper}))\n",
    "\n",
    "\n",
    "class Reverse:\n",
    "    \"\"\"Reverse each token. Designed to run in parallel with Uppercase.\"\"\"\n",
    "    requires = frozenset({\"tokens\"})\n",
    "    provides = frozenset({\"reversed_tokens\"})\n",
    "\n",
    "    def __call__(self, ctx: StepContext) -> StepContext:\n",
    "        rev = [t[::-1] for t in ctx.metadata[\"tokens\"]]\n",
    "        print(f\"    [Reverse]   {ctx.metadata['tokens']} → {rev}\")\n",
    "        return ctx.replace(metadata=MappingProxyType({**ctx.metadata, \"reversed_tokens\": rev}))\n",
    "\n",
    "\n",
    "class Summarize:\n",
    "    \"\"\"Combine processed metadata into a final agent_output string.\"\"\"\n",
    "    requires = frozenset({\"upper_tokens\", \"reversed_tokens\", \"word_count\"})\n",
    "    provides = frozenset({\"agent_output\"})\n",
    "\n",
    "    def __call__(self, ctx: StepContext) -> StepContext:\n",
    "        summary = (\n",
    "            f\"{ctx.metadata['word_count']} words | \"\n",
    "            f\"upper={ctx.metadata['upper_tokens']} | \"\n",
    "            f\"rev={ctx.metadata['reversed_tokens']}\"\n",
    "        )\n",
    "        print(f\"    [Summarize] → {summary}\")\n",
    "        return ctx.replace(agent_output=summary)\n",
    "\n",
    "\n",
    "class Boom:\n",
    "    \"\"\"Always fails — used to demonstrate error handling.\"\"\"\n",
    "    requires = frozenset()\n",
    "    provides = frozenset()\n",
    "\n",
    "    def __call__(self, ctx: StepContext) -> StepContext:\n",
    "        raise RuntimeError(f\"Boom on sample={ctx.sample!r}!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35014e6",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Basic Linear Pipeline\n",
    "\n",
    "Chain steps with `.then()`. The pipeline infers its **contracts**\n",
    "(`requires` / `provides`) from the step chain automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0814c427",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline().then(Tokenize()).then(Uppercase())\n",
    "\n",
    "print(\"Pipeline contracts:\")\n",
    "print(f\"  requires = {pipe.requires}   ← external inputs the caller must provide\")\n",
    "print(f\"  provides = {pipe.provides}   ← everything the pipeline writes\")\n",
    "print()\n",
    "\n",
    "results = pipe.run([\"hello world\", \"pipeline engine demo\"])\n",
    "show(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddad0e30",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Contract Validation\n",
    "\n",
    "The engine validates step ordering at **construction time**.\n",
    "If a step needs a field that a *later* step provides → `PipelineOrderError`.\n",
    "\n",
    "Fields not provided by *any* step are treated as **external inputs** — no error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f22a4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrong order: Uppercase needs 'tokens', but Tokenize comes after\n",
    "print(\"Trying: Pipeline().then(Uppercase()).then(Tokenize())\\n\")\n",
    "\n",
    "try:\n",
    "    Pipeline().then(Uppercase()).then(Tokenize())\n",
    "except PipelineOrderError as e:\n",
    "    print(f\"  Caught PipelineOrderError:\\n  {e}\\n\")\n",
    "\n",
    "# External input: 'tokens' not produced by anyone → valid, caller must provide it\n",
    "p = Pipeline().then(Uppercase())\n",
    "print(f\"External input is OK:  requires = {p.requires}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1489099b",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Branch — Parallel Fork/Join\n",
    "\n",
    "`.branch()` fans out to N child pipelines in parallel, then **merges**\n",
    "their outputs back into a single `StepContext`.\n",
    "\n",
    "```\n",
    "                 ┌── Uppercase ──┐\n",
    "  Tokenize ──►──┤               ├──► Summarize\n",
    "                 └── Reverse  ──┘\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c559cbae",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "pipe = (\n",
    "    Pipeline()\n",
    "    .then(Tokenize())\n",
    "    .branch(\n",
    "        Pipeline().then(Uppercase()),\n",
    "        Pipeline().then(Reverse()),\n",
    "        merge=MergeStrategy.RAISE_ON_CONFLICT,\n",
    "    )\n",
    "    .then(Summarize())\n",
    ")\n",
    "\n",
    "print(f\"requires = {pipe.requires}\")\n",
    "print(f\"provides = {pipe.provides}\\n\")\n",
    "\n",
    "results = pipe.run([\"fork join\"])\n",
    "show(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba7edad5",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Merge Strategies\n",
    "\n",
    "When branches write the **same named field**, the merge strategy decides what happens:\n",
    "\n",
    "| Strategy | Behaviour |\n",
    "|---|---|\n",
    "| `RAISE_ON_CONFLICT` | `ValueError` if any named field differs (metadata always LWW) |\n",
    "| `LAST_WRITE_WINS` | Last branch's value wins for every field |\n",
    "| `NAMESPACED` | Each branch stored at `metadata[\"branch_N\"]`, no conflict possible |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a49dd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WriteAnswer:\n",
    "    requires = frozenset()\n",
    "    provides = frozenset({\"agent_output\"})\n",
    "    def __init__(self, val: str):\n",
    "        self.val = val\n",
    "    def __call__(self, ctx):\n",
    "        return ctx.replace(agent_output=self.val)\n",
    "\n",
    "ctx = StepContext(sample=\"q\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c59d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a) RAISE_ON_CONFLICT — two branches write different values → error\n",
    "print(\"a) RAISE_ON_CONFLICT with conflict:\\n\")\n",
    "\n",
    "b = Branch(\n",
    "    Pipeline().then(WriteAnswer(\"yes\")),\n",
    "    Pipeline().then(WriteAnswer(\"no\")),\n",
    "    merge=MergeStrategy.RAISE_ON_CONFLICT,\n",
    ")\n",
    "try:\n",
    "    b(ctx)\n",
    "except ValueError as e:\n",
    "    print(f\"   Caught ValueError: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d814f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# b) LAST_WRITE_WINS — second branch always wins\n",
    "print(\"b) LAST_WRITE_WINS:\\n\")\n",
    "\n",
    "b = Branch(\n",
    "    Pipeline().then(WriteAnswer(\"yes\")),\n",
    "    Pipeline().then(WriteAnswer(\"no\")),\n",
    "    merge=MergeStrategy.LAST_WRITE_WINS,\n",
    ")\n",
    "out = b(ctx)\n",
    "print(f\"   agent_output = {out.agent_output!r}   ← second branch wins\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac780329",
   "metadata": {},
   "outputs": [],
   "source": [
    "# c) NAMESPACED — each branch isolated, accessible via metadata key\n",
    "print(\"c) NAMESPACED:\\n\")\n",
    "\n",
    "b = Branch(\n",
    "    Pipeline().then(WriteAnswer(\"yes\")),\n",
    "    Pipeline().then(WriteAnswer(\"no\")),\n",
    "    merge=MergeStrategy.NAMESPACED,\n",
    ")\n",
    "out = b(ctx)\n",
    "print(f\"   agent_output          = {out.agent_output!r}   ← from first branch\")\n",
    "print(f\"   branch_0.agent_output = {out.metadata['branch_0'].agent_output!r}\")\n",
    "print(f\"   branch_1.agent_output = {out.metadata['branch_1'].agent_output!r}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d626b1c3",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Error Handling\n",
    "\n",
    "Every sample produces a `SampleResult` — nothing is dropped silently.\n",
    "A failing sample sets `error` and `failed_at`; other samples continue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577e2e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"All samples fail:\\n\")\n",
    "results = Pipeline().then(Tokenize()).then(Boom()).run([\"good luck\"])\n",
    "show(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62824a52",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "print(\"Mixed success / failure:\\n\")\n",
    "\n",
    "class MaybeBoom:\n",
    "    requires = frozenset()\n",
    "    provides = frozenset()\n",
    "    def __call__(self, ctx):\n",
    "        if \"bad\" in str(ctx.sample):\n",
    "            raise RuntimeError(\"bad sample!\")\n",
    "        return ctx\n",
    "\n",
    "results = Pipeline().then(Tokenize()).then(MaybeBoom()).run([\"ok\", \"bad input\", \"fine\"])\n",
    "show(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6261bf1e",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Async Boundary — Fire-and-Forget Background\n",
    "\n",
    "Set `async_boundary = True` on a step. Everything from that step onward\n",
    "runs in a **background thread**. `run()` returns immediately.\n",
    "\n",
    "```\n",
    "  Foreground (fast)         Background (slow)\n",
    "  ┌──────────┐             ┌───────────┐\n",
    "  │ Tokenize │ ──────►──── │ SlowScore │\n",
    "  └──────────┘             └───────────┘\n",
    "       │                        │\n",
    "    run() returns          updated later\n",
    "```\n",
    "\n",
    "Call `wait_for_background()` to join all background threads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84bca63",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SlowScore:\n",
    "    \"\"\"Expensive scoring step that runs in background.\"\"\"\n",
    "    requires = frozenset()\n",
    "    provides = frozenset({\"score\"})\n",
    "    async_boundary = True\n",
    "    max_workers = 2\n",
    "\n",
    "    def __call__(self, ctx: StepContext) -> StepContext:\n",
    "        time.sleep(0.1)\n",
    "        score = ctx.metadata.get(\"word_count\", 0) * 10\n",
    "        print(f\"    [SlowScore] sample={ctx.sample!r} score={score}  (background)\")\n",
    "        return ctx.replace(metadata=MappingProxyType({**ctx.metadata, \"score\": score}))\n",
    "\n",
    "pipe = Pipeline().then(Tokenize()).then(SlowScore())\n",
    "\n",
    "t0 = time.monotonic()\n",
    "results = pipe.run([\"fast return\", \"also fast\"], workers=2)\n",
    "elapsed = time.monotonic() - t0\n",
    "\n",
    "print(f\"\\nrun() returned in {elapsed:.3f}s — background still scoring\\n\")\n",
    "show(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db875020",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now wait for background to finish and inspect the updated results\n",
    "print(\"Waiting for background...\\n\")\n",
    "pipe.wait_for_background(timeout=5.0)\n",
    "print(\"Done!\\n\")\n",
    "show(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3805436",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Nested Pipelines\n",
    "\n",
    "A `Pipeline` satisfies `StepProtocol`, so it can be used as a step\n",
    "inside another pipeline. Contracts are inferred recursively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f21c83b",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "inner = Pipeline().then(Tokenize()).then(Uppercase())\n",
    "outer = Pipeline().then(inner).then(Reverse())\n",
    "\n",
    "print(f\"Inner: requires={inner.requires}, provides={inner.provides}\")\n",
    "print(f\"Outer: requires={outer.requires}, provides={outer.provides}\\n\")\n",
    "\n",
    "results = outer.run([\"nested demo\"])\n",
    "show(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eedb5cd",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. Workers — Concurrent Sample Processing\n",
    "\n",
    "The `workers` parameter on `run()` controls how many samples are processed\n",
    "in parallel (via an `asyncio.Semaphore` in the foreground event loop).\n",
    "This is independent of `max_workers` on individual steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe86852",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SlowStep:\n",
    "    requires = frozenset()\n",
    "    provides = frozenset({\"done\"})\n",
    "    def __call__(self, ctx):\n",
    "        time.sleep(0.1)\n",
    "        return ctx.replace(metadata=MappingProxyType({**ctx.metadata, \"done\": True}))\n",
    "\n",
    "samples = [f\"s{i}\" for i in range(6)]\n",
    "pipe = Pipeline().then(SlowStep())\n",
    "\n",
    "t0 = time.monotonic()\n",
    "pipe.run(samples, workers=1)\n",
    "seq = time.monotonic() - t0\n",
    "\n",
    "t0 = time.monotonic()\n",
    "pipe.run(samples, workers=6)\n",
    "par = time.monotonic() - t0\n",
    "\n",
    "print(f\"  workers=1 : {seq:.2f}s\")\n",
    "print(f\"  workers=6 : {par:.2f}s\")\n",
    "print(f\"  speedup   : {seq / par:.1f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b426125",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary\n",
    "\n",
    "| Concept | API |\n",
    "|---|---|\n",
    "| Linear chain | `Pipeline().then(A()).then(B())` |\n",
    "| Contract inference | `pipe.requires`, `pipe.provides` |\n",
    "| Parallel fork/join | `.branch(Pipeline().then(A()), Pipeline().then(B()))` |\n",
    "| Merge control | `merge=MergeStrategy.RAISE_ON_CONFLICT / LAST_WRITE_WINS / NAMESPACED` |\n",
    "| Error isolation | `SampleResult.error`, `SampleResult.failed_at` |\n",
    "| Background execution | `async_boundary = True` on a step class |\n",
    "| Background join | `pipe.wait_for_background(timeout=...)` |\n",
    "| Nesting | Use a `Pipeline` as a step inside another `Pipeline` |\n",
    "| Sample concurrency | `pipe.run(samples, workers=N)` |\n",
    "\n",
    "The pipeline engine is **domain-agnostic** — it knows nothing about ACE.\n",
    "The `ace2/` package will add domain-specific steps (Agent, Evaluate,\n",
    "Reflect, Update) on top of this engine."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "executable": "/usr/bin/env python3",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
